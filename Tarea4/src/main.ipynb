{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d7137e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a733ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jtapi/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jtapi/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\jtapi/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MiDaS v3.1\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\").to(device).eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform_midas = midas_transforms.default_transform\n",
    "\n",
    "# Depth Anything V2 (Hugging Face)\n",
    "processor = AutoImageProcessor.from_pretrained(\"depth-anything/Depth-Anything-V2-Large-hf\")\n",
    "depth_anything = AutoModelForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Large-hf\").to(device).eval()\n",
    "\n",
    "# YOLOv11 (entrenado por ayudante)\n",
    "yolo = YOLO(\"yolo11s.pt\")  # Reemplaza con la ruta correcta si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08855f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_profundidad_midas(img, model, transform):\n",
    "    input_batch = transform(img).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_batch)\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "def estimar_profundidad_depth_anything_v2(img):\n",
    "    img_pil = Image.fromarray(img)\n",
    "    inputs = processor(images=img_pil, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = depth_anything(**inputs).predicted_depth\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img_pil.size[::-1],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "def detectar_y_medir_distancia(img, depth_map, model, conf=0.6):\n",
    "    results = model.predict(img, conf=conf, verbose=False)[0]\n",
    "    detecciones = []\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cls = int(box.cls[0])\n",
    "        confianza = float(box.conf[0])\n",
    "        label = model.names[cls]\n",
    "        roi = depth_map[y1:y2, x1:x2]\n",
    "        distancia = np.median(roi) if roi.size else 0\n",
    "        detecciones.append({\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"label\": label,\n",
    "            \"confianza\": confianza,\n",
    "            \"distancia\": round(float(distancia), 2)\n",
    "        })\n",
    "    return detecciones\n",
    "\n",
    "def dibujar_detecciones(img, detecciones):\n",
    "    salida = img.copy()\n",
    "    for det in detecciones:\n",
    "        x1, y1, x2, y2 = det[\"bbox\"]\n",
    "        texto = f'{det[\"label\"]} {det[\"confianza\"]:.2f} | {det[\"distancia\"]} m'\n",
    "        cv2.rectangle(salida, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(salida, texto, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
    "    return salida\n",
    "\n",
    "def resize_img(img, height=200):\n",
    "    aspect_ratio = img.shape[1] / img.shape[0]\n",
    "    return cv2.resize(img, (int(height * aspect_ratio), height))\n",
    "\n",
    "def guardar_mapa_profundidad(depth_map, ruta_salida):\n",
    "    norm = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map) + 1e-8)\n",
    "    plt.imsave(ruta_salida, norm, cmap=\"inferno\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0689d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "frames_dir = Path(\"../frames\")\n",
    "out_root = Path(\"../outputs\")\n",
    "out_midas = out_root / \"modelo_midas\"\n",
    "out_da = out_root / \"modelo_depth_anything\"\n",
    "out_yolo_midas = out_root / \"modelo_midas_yolo\"\n",
    "out_yolo_da = out_root / \"modelo_depth_anything_yolo\"\n",
    "out_summary = Path(\"../summarize\")\n",
    "\n",
    "# Crear carpetas\n",
    "for p in [out_midas, out_da, out_yolo_midas, out_yolo_da, out_summary]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Leer 5 imágenes\n",
    "frame_paths = sorted([p for p in frames_dir.glob(\"*.jpg\")])[:5]\n",
    "frames = [cv2.cvtColor(cv2.imread(str(p)), cv2.COLOR_BGR2RGB) for p in frame_paths]\n",
    "frame_names = [p.stem for p in frame_paths]\n",
    "\n",
    "# Procesar y guardar todo\n",
    "resumen_filas = []\n",
    "\n",
    "\n",
    "\n",
    "# Crear resumen visual tipo plot (1 fila x 5 columnas)\n",
    "for frame, name in zip(frames, frame_names):\n",
    "    # Estimar mapas\n",
    "    depth_midas = estimar_profundidad_midas(frame, midas, transform_midas)\n",
    "    depth_da = estimar_profundidad_depth_anything_v2(frame)\n",
    "\n",
    "    # Guardar mapas\n",
    "    guardar_mapa_profundidad(depth_midas, out_midas / f\"{name}_midas.png\")\n",
    "    guardar_mapa_profundidad(depth_da, out_da / f\"{name}_da.png\")\n",
    "\n",
    "    # YOLO detección\n",
    "    det_midas = detectar_y_medir_distancia(frame, depth_midas, yolo)\n",
    "    det_da = detectar_y_medir_distancia(frame, depth_da, yolo)\n",
    "\n",
    "    # Dibujar y guardar detecciones\n",
    "    img_yolo_midas = dibujar_detecciones(frame, det_midas)\n",
    "    img_yolo_da = dibujar_detecciones(frame, det_da)\n",
    "    cv2.imwrite(str(out_yolo_midas / f\"{name}_midas_yolo.png\"), cv2.cvtColor(img_yolo_midas, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(str(out_yolo_da / f\"{name}_da_yolo.png\"), cv2.cvtColor(img_yolo_da, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24725623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imagen resumen final 5x5 guardada como: ..\\summarize\\comparativa_summary_total.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Re-ensamblar los componentes para el plot completo\n",
    "fig, axs = plt.subplots(5, 5, figsize=(20, 16))\n",
    "column_titles = [\"Original\", \"Prof. MiDaS\", \"Prof. Depth Anything\", \"YOLO + MiDaS\", \"YOLO + Depth Anything\"]\n",
    "\n",
    "for row_idx, (frame, name) in enumerate(zip(frames, frame_names)):\n",
    "    # Cargar imágenes procesadas\n",
    "    img_orig = frame\n",
    "    img_midas = cv2.cvtColor(cv2.imread(str(out_midas / f\"{name}_midas.png\")), cv2.COLOR_BGR2RGB)\n",
    "    img_da = cv2.cvtColor(cv2.imread(str(out_da / f\"{name}_da.png\")), cv2.COLOR_BGR2RGB)\n",
    "    img_yolo_midas = cv2.cvtColor(cv2.imread(str(out_yolo_midas / f\"{name}_midas_yolo.png\")), cv2.COLOR_BGR2RGB)\n",
    "    img_yolo_da = cv2.cvtColor(cv2.imread(str(out_yolo_da / f\"{name}_da_yolo.png\")), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Agregar a cada celda del plot\n",
    "    row_images = [img_orig, img_midas, img_da, img_yolo_midas, img_yolo_da]\n",
    "    for col_idx, img in enumerate(row_images):\n",
    "        axs[row_idx, col_idx].imshow(img)\n",
    "        axs[row_idx, col_idx].axis(\"off\")\n",
    "        if row_idx == 0:\n",
    "            axs[row_idx, col_idx].set_title(column_titles[col_idx], fontsize=14)\n",
    "\n",
    "# Ajustar diseño y guardar\n",
    "plt.tight_layout()\n",
    "summary_final_path = out_summary / \"comparativa_summary_total.png\"\n",
    "plt.savefig(summary_final_path)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"✅ Imagen resumen final 5x5 guardada como: {summary_final_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
